{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "voAS4e-XbWaH"
   },
   "source": [
    "# Assignment - 1\n",
    "\n",
    "### Prasoon Sinha (eid), Evan King (ek8755)\n",
    "\n",
    "### Due: 11:59 PM CT, September 7\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-1QeRVC6S-X2"
   },
   "source": [
    "\n",
    "Assignment 1\n",
    "\n",
    "Total points: 75\n",
    "\n",
    "Due: Thursday, September 7 submitted via Canvas by 11:59 pm\n",
    "\n",
    "Your homework should be written in a Python notebook. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas. But be sure to include name and UT EID for both students.\n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7S3_aB9bIzRp"
   },
   "source": [
    "# Question 0:\n",
    "\n",
    "Fill out the survey posted in Canvas under Modules --> Quizzes by the same deadline as this assignment to receive a participation credit worth 5 assignment points.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh_WVVdznfMN"
   },
   "source": [
    "# Question 1: Judgement Under Uncertainty (5 pts)\n",
    "\n",
    "Read the article by Tversky and Kahneman (file name 'Tversky_Kahneman_1974' on Canvas under Modules) on Judgment under Uncertainty. Describe in your own words why judgments based on similarity or \"representativeness\" are prone to errors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging based on representativeness (i.e., \"the degree to which [event] A resembles [process] B\") can lead to errors because our measurement of representativeness is not affected by the same factors that influence the actual probability of an outcome. There are many situations in which A appears highly _representative_ of B, but the _probability_ that A arises from B is nonetheless low (or vice-versa). Following are three examples where the representativeness of a situation is not an accurate indicator of the true probability of a given outcome.\n",
    "\n",
    "1. _Prior probability._ We may already have a prior probability that, e.g., a randomly-sampled member of the population has a certain job. However, if we guess the individual's profession based on description of their personality, we may do it based on how well a stereotype of their personality suits the profession rather than based on the actual prior probability or base-rate frequency of different professions in the population.\n",
    "\n",
    "2. _Sample size._ If we are comparing two random, differently-sized sets of samples from a population, we may overestimate the accuracy of the proportion of samples in the smaller set if it is skewed toward a certain outcome. When drawing balls from a jar, for instance, we may find that 2/3 of draws are red in a smaller sample while 1/3 are red in a larger sample. This can lead us to believe that the 2/3 proportion in the smaller sample says more about the distribution because of its representativeness (i.e., a greater number of them are red), even though the sample size is larger for the 1/3 outcome (and thus closer to the true distribution).\n",
    "\n",
    "3. _Regression toward the mean._ The outcomes of events tend to move toward the mean of the population  (i.e., regression toward the mean) when the true distribution is Gaussian. However, we tend to assume that, e.g., a group of stellar students will always achieve scores above the mean of the population. This can lead us to more harshly judge later regressions toward the mean (e.g., lower test scores) in subsequent outcomes if we base our decision on representativeness (\"great students always perform well\") rather than the actual probability.\n",
    "\n",
    "In addition to these, Tversky and Kahneman describe several other errors that arise from the representativeness heuristic:\n",
    "\n",
    "- _\"Misconceptions of chance,\"_ where we expect that the properties of a population will be apparent both locally in small sequences and globally in longer sequences. A sequence of coin flips \"H-H-H-T\" seems less representative or \"fair\" than \"H-T-H-T\" even though both can result from the same distribution.\n",
    "\n",
    "- _\"Insensitivity to predictability,\"_ where we assume that qualitative descriptions of things can allow us to predict representative outcomes that are, in truth, unpredictable (e.g., predicting stock market performance based on a description of a company).\n",
    "\n",
    "- _\"The illusion of validity,\"_ where redundant input variables hint at representativeness and thus increase confidence in predictions, despite the fact that redundant input variables are known to lower the accuracy of predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IkVxrWs0o0tn"
   },
   "source": [
    "\n",
    "# Question 2: Google Flu Trends (10 pts)\n",
    "\n",
    "The second article posted  in Canvas under Modules --> Resources, (google flu) describes a high-profile (and embarrassingly  failed)  project done by google, highlighting the phenomena of data drift and the importance of continually monitoring/updating models post deployment.\n",
    "\n",
    "Read this article and then briefly describe\n",
    "\n",
    "(i) three important causes of \"data drift\" in the flu prediction problem that are mentioned in the article, and\n",
    "\n",
    "(ii) one important aspect of the original google model design that made it very prone to overfitting (and hence poor generalization on future data).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hpTvwLiHVmfo"
   },
   "source": [
    "# Question 3: Maximum Likelihood Estimate (10 pts)\n",
    "\n",
    "Assume there is a 4-sided dice, each roll of the dice can result into a possible outcome in {1, 2, 3, 4}. Suppose a random sample of 30 students of your class independently rolled the dice and their outcomes were recorded as below:\n",
    "$$\n",
    "[4,2,1,4,2,2,4,1,1,2,1,2,3,3,1,1,4,1,1,4,3,4,1,3,3,1,1,3,1,2]\n",
    "$$\n",
    "If $p_i$ refers to the probability of the dice landing on the number $i$, i.e., probability that dice lands on 1 is $p_1$, lands on 2 is $p_2$ and so on.\n",
    "\n",
    "1. Based on these definitions, write the log-likelihood of observing the above given sequence of outcomes. (5 points) (Hint : Think multinomial distribution.)\n",
    "2. Now to infer the probabilities {$p_1, p_2, p_3, p_4$} from the observed data, we need to maximize the log-likelihood for each $p_i$ individually. What (if any) is the problem with maximizing the above found log-likelihood wrt $p_i$ directly? And how can we overcome this problem? (5 points) (Hint : Think about the solutions, i.e., the values of $p_i$'s that we obtain in order to maximize the log-likelihood, and if they are correct.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nTWFVcvwXP4w"
   },
   "source": [
    "# Question 4: Linear Regression (10 pts)\n",
    "\n",
    "1. What is the difference between R-square and adjusted R square and why is it desirable to use the adjusted value? (4 pts)\n",
    "\n",
    "    R-squared is an accuracy measure of a regression model on the data the model was trained on. It specifies how much of the variance in the predicted variable is explained by the indepedent variables. Adjusted R-squared is a metric that suggests how the model will perform on unseen, future samples. When there are multiple indepedent variables, the R-square value can become inflated; that is; as we increase the number of independent variables, the R-squared value either stays the same or increases. However, some independent variables may not be useful in predicting the target variable. The adjusted R-squared value deals with this issue by accounting for the number of independent variables, enabling us to understand whether adding new independent variables improved the model.\n",
    "\n",
    "2. Overfitting usually happens in complex models. Linear Regression is a fairly simple model. Could overfitting happen in Linear Regression? If so, please explain the scenario in which it could happen and how we can tackle it. (6 pts)\n",
    "\n",
    "    Overfitting could occur in Linear Regression. Linear regressors are especially prone to overfitting when the number of parameters is larger than the number of samples. Hence, the linear regressor's coefficients represent the noise in the data rather than the true relationship between the variables. One great way to tackle this issue is by obtaining more samples to train the data on. However, if this is not possible, there are other options we could take:\n",
    "    - Data Augmentation: make a sample look slightly different every time it is processed by the model, hence making data sets appear unique\n",
    "    - Cross-validation: we generate multiple small train/test splits using our testing data and use these splits to tune our model\n",
    "    - Feature Selection: improve model generalizability by removing irrelevant input features\n",
    "    - Regularization: a technique that penalizes the loss function furthe to prevent the complexity of the linear regressor, forms of this inclue lassor and ridge regularizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IvIs1fklzWoY"
   },
   "source": [
    "# Question 5: Ridge/ Lasso Regression (35 pts)\n",
    "\n",
    "This is a programming question. Please read through each subpart of this question carefully. You are required to add lines of code as specified in the code cells. Please carefully read through the comments in the code cells to identify what code is to be written, where it is to be written and how many lines of code are required. Code is to be added between the **## START CODE** ## and **## END CODE ##** comments and in place of the keyword **None**. In certain cases, the number of lines of code that are to be written will be specified. For example, **## START CODE ## (1 line of code)** specifies that only 1 line of code is to be added between the ## START CODE ## and ## END CODE ## comments. In case there is no information on the required number of lines, you are allowed to add any number of lines of code.\n",
    "\n",
    "The following question covers the California housing prices dataset and linear models in python. The dataset is taken from https://www.kaggle.com/camnugent/california-housing-prices/version/1. The categorical variables and rows with missing variables are removed to make it easier to run the models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NQphDrEczWoY"
   },
   "source": [
    "The data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data. The columns are as follows:\n",
    "\n",
    "* longitude\n",
    "* latitude\n",
    "* housingmedianage\n",
    "* total_rooms\n",
    "* total_bedrooms\n",
    "* population\n",
    "* households\n",
    "* median_income\n",
    "* medianhousevalue\n",
    "* ocean_proximity (this feature has been removed from the csv file since it is an ordinal variable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "16G3O_XNzWoZ"
   },
   "source": [
    "NOTE\n",
    "* Only use the following code block if you are using Google Colab. If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
    "* It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "S2rMKQQgzWoZ",
    "outputId": "412f825a-4db6-4372-8e78-be0de61bd3a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2be02b6a-c055-46f9-a986-a4f09f51c64e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-2be02b6a-c055-46f9-a986-a4f09f51c64e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving housing_data.csv to housing_data.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IuWW6gn_zWoZ"
   },
   "source": [
    "Imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B21q-bx4zWoZ"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "df = pd.read_csv(\"housing_data.csv\")\n",
    "X = df.drop(['median_house_value'],axis=1)\n",
    "Y = df['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dj9kqISxzWoa",
    "outputId": "c468e372-a820-45db-c5a9-c1eed7086c39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show you all the columns in this file\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "plE_OXorzWoa",
    "outputId": "ce5a4335-6fe8-45a9-e8cb-3d43faaf4b5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bd624898-d8e6-474b-9399-0f113b30160b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd624898-d8e6-474b-9399-0f113b30160b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bd624898-d8e6-474b-9399-0f113b30160b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bd624898-d8e6-474b-9399-0f113b30160b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-78df1249-8ef1-4faa-8154-ea3c16f96168\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78df1249-8ef1-4faa-8154-ea3c16f96168')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-78df1249-8ef1-4faa-8154-ea3c16f96168 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0       322.0       126.0         8.3252            452600.0  \n",
       "1      2401.0      1138.0         8.3014            358500.0  \n",
       "2       496.0       177.0         7.2574            352100.0  \n",
       "3       558.0       219.0         5.6431            341300.0  \n",
       "4       565.0       259.0         3.8462            342200.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show you the first 5 rows in this file\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWVtzFlZzWoa"
   },
   "source": [
    "## Part-1: *(2 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "altrF0ONzWoa"
   },
   "source": [
    "Split the data into a training set (75% of data) and a test set (25% of data), using the train_test_split function with random_state = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ0QGMfLzWoa"
   },
   "outputs": [],
   "source": [
    "##  START CODE  ## (1 line of code)\n",
    "X_train, X_test, y_train, y_test = None\n",
    "##  END CODE    ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "p12PihqIzWoa"
   },
   "source": [
    "Scale the data (not including target) so that each of the independent variables would have zero mean and unit variance. You can use the sklearn.preprocessing.scale function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyLKGFRtzWoa"
   },
   "outputs": [],
   "source": [
    "##  START CODE  ## (2 lines of code)\n",
    "Xscaled_train = None\n",
    "Xscaled_test = None\n",
    "##  END CODE    ##\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WMIQVrijzWoa"
   },
   "source": [
    "Print the first 5 rows of the training set after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiN26WrEzWoa"
   },
   "outputs": [],
   "source": [
    "##  START CODE  ##\n",
    "##  END CODE    ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sWPxRJlVzWoa"
   },
   "source": [
    "Select any two variables. See how their histograms and scatterplots compare before and after scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62kY3ExAzWoa"
   },
   "outputs": [],
   "source": [
    "##  START CODE  ##\n",
    "##  END CODE    ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KawI2XbhzWob"
   },
   "source": [
    "> *Answer here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sHlAhbauzWob"
   },
   "source": [
    "## Part-2: *(5 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0RT99GSzzWob"
   },
   "source": [
    "Use `sklearn.linear_model.Lasso` and `sklearn.linear_model.Ridge` classes to do a 5-fold cross validation using sklearn's `KFold`. For the sweep of the regularization parameter, we will look at a grid of values ranging from  $\\alpha=10^{-6}$  to  $\\alpha=10^{6}$.In Python, you can consider this range of values as follows: `alpha = 10**numpy.linspace(-6, 6, 100)` so that you can generate 100 uniform values between -6 to 6 as power series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KW5FcTDRzWob"
   },
   "source": [
    "Fit the 2 regression models (Lasso and Ridge) with scaled data and report the best chosen $\\alpha$ based on cross validation as well as the corresponding scoring metric. The cross validation should happen on your training data using MSE as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TE4l9nLEBo6z"
   },
   "outputs": [],
   "source": [
    "# Define number of folds\n",
    "##  START CODE  ## (1 line of code)\n",
    "n_folds = None\n",
    "##  END CODE  ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hTeW3JKF8ml"
   },
   "outputs": [],
   "source": [
    "# Create KFold from sklearn\n",
    "##  START CODE  ## (1 line of code)\n",
    "k_fold = None\n",
    "##  END CODE    ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjKRXwTFzWob"
   },
   "outputs": [],
   "source": [
    "#Define the alphas as defined in the question\n",
    "##  START CODE  ## (1 line of code)\n",
    "alphas = None\n",
    "##  END CODE    ##\n",
    "\n",
    "lasso_avg_mse = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-VBrbOnCgm4"
   },
   "outputs": [],
   "source": [
    "#For each value of alpha and each fold compute the mean square error\n",
    "for alpha in alphas:\n",
    "\n",
    "  #Instantiate a lasso model with the current alpha\n",
    "  ##  START CODE  ## (1 line of code)\n",
    "  lasso = None\n",
    "  ##  END CODE    ##\n",
    "\n",
    "  avg_mse = 0\n",
    "\n",
    "  for k, (train, test) in enumerate(k_fold.split(X_train, Y_train)):\n",
    "\n",
    "    #Fit the scaled training data to the lasso model\n",
    "    ## START CODE ## (1 line of code)\n",
    "\n",
    "    ## END CODE ##\n",
    "\n",
    "    #Calculate the average mean sqaured error\n",
    "    ##  START CODE  ## (1 line of code)\n",
    "    avg_mse = None\n",
    "    ##  END CODE    ##\n",
    "\n",
    "  # Take the average mean squared error as metric\n",
    "  lasso_avg_mse[alpha] = avg_mse / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4CM_0joFe8S"
   },
   "outputs": [],
   "source": [
    "# Find the best value for alpha with minimum mean squared error\n",
    "##  START CODE  ## (1 line of code)\n",
    "best_alpha_lasso = None\n",
    "##  END CODE    ##\n",
    "\n",
    "print(\"Best lasso alpha: {}\".format(best_alpha_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXcr50EVG71p"
   },
   "outputs": [],
   "source": [
    "#For each value of alpha and each fold compute the mean square error\n",
    "for alpha in alphas:\n",
    "\n",
    "  #Instantiate a ridge model with the current alpha\n",
    "  ##  START CODE  ## (1 line of code)\n",
    "  ridge = None\n",
    "  ##  END CODE    ##\n",
    "\n",
    "  avg_mse = 0\n",
    "\n",
    "  for k, (train, test) in enumerate(k_fold.split(X_train, Y_train)):\n",
    "\n",
    "    #Fit the scaled training data to the ridge model\n",
    "    ## START CODE ## (1 line of code)\n",
    "\n",
    "    ## END CODE ##\n",
    "\n",
    "    #Calculate the average mean sqaured error\n",
    "    ##  START CODE  ## (1 line of code)\n",
    "    avg_mse = None\n",
    "    ##  END CODE    ##\n",
    "\n",
    "  # Take the average mean squared error as metric\n",
    "  ridge_avg_mse[alpha] = avg_mse / n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1LiJKj3HRpV"
   },
   "outputs": [],
   "source": [
    "# Find the best value for alpha with minimum mean squared error\n",
    "##  START CODE  ## (1 line of code)\n",
    "best_alpha_ridge = None\n",
    "##  END CODE    ##\n",
    "\n",
    "print(\"Best ridge alpha: {}\".format(best_alpha_ridge))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Qs4ytzCHzWob"
   },
   "source": [
    "## Part-3: *(7 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ebGlK_-KzWob"
   },
   "source": [
    "Run ridge and lasso regression for all of the $\\alpha$ specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; different features' weights of each model should be on the same plot with different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dk560hkwzWob"
   },
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=alpha)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "  #Specify current alpha as parameter for the lasso model\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##\n",
    "\n",
    "  #Fit the training data to the lasso model\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##\n",
    "\n",
    "  #Store learned coefficients in the coef variable\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFxhwgHNY1wL"
   },
   "outputs": [],
   "source": [
    "# Write the code to make the plot for coefficients learned from lasso\n",
    "## START CODE ##\n",
    "\n",
    "## END CODE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRiJhDbCWHYJ"
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "\n",
    "ridge = linear_model.Ridge(alpha=alpha)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "  #Specify current alpha as parameter for the ridge model\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##\n",
    "\n",
    "  #Fit the training data to the ridge model\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##\n",
    "\n",
    "  #Store learned coefficients in the coef variable\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6mWtQWAY_05"
   },
   "outputs": [],
   "source": [
    "# Write the code to make the plot for coefficients learned from ridge\n",
    "## START CODE ##\n",
    "\n",
    "## END CODE ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "u4ToCYI_zWob"
   },
   "source": [
    "What do you qualitatively observe when the value of the regularization parameter changes?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CGioS5clzWob"
   },
   "source": [
    "> *Answer here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KNuyxETgzWoc"
   },
   "source": [
    "## Part-4: *(5 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl4QyJ8RzWoc"
   },
   "source": [
    "Similarly, use `sklearn.linear_model.ElasticNet` to do linear regression with different $\\alpha$ values, and plot the coefficients learned for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAb8VHJyzWoh"
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "\n",
    "ElastNet = linear_model.ElasticNet(alpha=alpha)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "  #Specify current alpha as parameter for the ElasticNet model\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##\n",
    "\n",
    "  #Fit the training data to the ElasticNet model\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##\n",
    "\n",
    "  #Store learned coefficients in the coef variable\n",
    "  ## START CODE ## (1 line of code)\n",
    "\n",
    "  ## END CODE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiAe5JkaZTez"
   },
   "outputs": [],
   "source": [
    "# Write the code to make the plot for coefficients learned from ElasticNet\n",
    "## START CODE ##\n",
    "\n",
    "## END CODE ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5aPjEz4azWoh"
   },
   "source": [
    "Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R0VhGFq8zWoh"
   },
   "source": [
    "> *Answer here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lsr0eyXxzWoi"
   },
   "source": [
    "## Part-5: *(10 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6oK1Mplulr9g"
   },
   "source": [
    "Run the following three regression models with MSE loss on the training data:\n",
    "\n",
    "a. linear regression without regularization\n",
    "\n",
    "b. linear regression with ridge regularization\n",
    "\n",
    "c. linear regression with lasso regularization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UCgN_M8FmFy0"
   },
   "source": [
    "\n",
    "For part (b) and (c), use only the best regularization parameters. Report the MSE and R2 on the test data for each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vInxZtUl01E"
   },
   "outputs": [],
   "source": [
    "## START CODE ##\n",
    "\n",
    "## END CODE ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YaTLxColzWoi"
   },
   "source": [
    "## Part-6: *(3 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LyEUlDFEzWoi"
   },
   "source": [
    "Train the 3 models and report metrics with the original data without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Abt6faNNzWoi"
   },
   "outputs": [],
   "source": [
    "##  START CODE  ##\n",
    "\n",
    "##  END CODE    ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SjLMZ2DgzWoi"
   },
   "source": [
    "## Part-7: *(3 pts)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VA_dCZlRzWoi"
   },
   "source": [
    "Why is it advisable to scale the independent variables when applying ridge or  lasso regression?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
